<html>
<!DOCTYPE html>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>十、分片内部原理</title>
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
	<link rel="stylesheet" href="../css/bootstrap.min.css">
	<link rel="stylesheet" href="../css/font-awesome.min.css">
    <link rel="stylesheet" href="../plugins/ckeditor/plugins/codesnippet/lib/highlight/styles/googlecode.css">
    <link rel="stylesheet" type="text/css" href="../css/front/screen.css">
    <script src="../plugins/ckeditor/plugins/codesnippet/lib/highlight/highlight.pack.js"></script>
	<style type="text/css">
		.list{
			margin-top:5em;
			position: fixed;
		}
		
		.list h4{
			padding-bottom:0.5em;
			border-bottom:2px solid lightgray;
		}
		
		.list .readTitle li{
			margin-top:0.4em;
			padding-left:1em;
			border:2px solid white;
		}
		.list .readTitle li:hover{
			border-left:2px solid black;
			color:blue;
		}
		.liHover{
			border-left:2px solid black !important;
		}
		.aHover{
			color:blue;
		}
		.list .readTitle li a:hover{
			color:blue;
			text-decoration: none;
		}
	</style>
</head>
<body>
    <section class="content-wrap container-fluid">
        <div class="container">
            <div class="row">
				<div class="col-md-3 visible-lg-block visible-md-block">
					<div class="list">
						<h4>阅读目录</h4>
						<div>
							<ul class="readTitle list-unstyled"></ul>
						</div>
					</div>
				</div>
                 <main class="col-md-19 main-content">
					<article class="post row">
					<header class="post-head">
				        <h1 class="post-title">十、分片内部原理</h1>
				        <section class="post-meta">
					        <span><span class="glyphicon glyphicon-user"></span>:<span>c</span></span>|
				            <span><span class="glyphicon glyphicon-bookmark"></span>:<span>Elasticsearch</span></span>|
				            <span><span class="glyphicon glyphicon-time"></span>:<span>2018-06-27</span></span>
				        </section>
				    </header>
				    <section class="post-content"><h2>分片内部原理</h2>

<p>在&nbsp;<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/distributed-cluster.html" title="集群内的原理"><em>集群内的原理</em></a>, 我们介绍了&nbsp;<em>分片</em>, 并将它&nbsp;描述成最小的&nbsp;<em>工作单元_。但是究竟什么 _是</em>&nbsp;一个分片，它是如何工作的？ 在这个章节，我们回答以下问题:</p>

<ul style="list-style-type:disc">
	<li>为什么搜索是&nbsp;<em>近</em>&nbsp;实时的？</li>
	<li>为什么文档的 CRUD (创建-读取-更新-删除) 操作是&nbsp;<em>实时</em>&nbsp;的?</li>
	<li>Elasticsearch 是怎样保证更新被持久化在断电时也不丢失数据?</li>
	<li>为什么删除文档不会立刻释放空间？</li>
	<li><code>refresh</code>,&nbsp;<code>flush</code>, 和&nbsp;<code>optimize</code>&nbsp;API 都做了什么, 你什么情况下应该是用他们？</li>
</ul>

<p>最简单的理解一个分片如何工作的方式是上一堂历史课。 我们将要审视提供一个带近实时搜索和分析的 分布式持久化数据存储需要解决的问题。</p>

<h2>使文本可被搜索</h2>

<p>必须解决的第一个挑战是如何&nbsp;使文本可被搜索。 传统的数据库每个字段存储单个值，但这对全文检索并不够。文本字段中的每个单词需要被搜索，对数据库意味着需要单个字段有索引多值(这里指单词)的能力。</p>

<p>最好的支持&nbsp;<em>一个字段多个值</em>&nbsp;需求的数据结构是我们在&nbsp;<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/inverted-index.html" title="倒排索引">倒排索引</a>&nbsp;章节中介绍过的&nbsp;<em>倒排索引</em>&nbsp;。 倒排索引包含一个有序列表，列表包含所有文档出现过的不重复个体，或称为&nbsp;<em>词项</em>&nbsp;，对于每一个词项，包含了它所有曾出现过文档的列表。</p>

<pre>
Term  | Doc 1 | Doc 2 | Doc 3 | ...
------------------------------------
brown |   X   |       |  X    | ...
fox   |   X   |   X   |  X    | ...
quick |   X   |   X   |       | ...
the   |   X   |       |  X    | ...</pre>

<p><img alt="注意" src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/icons/note.png" /></p>

<p>当讨论倒排索引时，我们会谈到&nbsp;<em>文档</em>&nbsp;标引，因为历史原因，倒排索引被用来对整个非结构化文本文档进行标引。 Elasticsearch 中的&nbsp;<em>文档</em>&nbsp;是有字段和值的结构化 JSON 文档。事实上，在 JSON 文档中， 每个被索引的字段都有自己的倒排索引。</p>

<p>这个倒排索引相比特定词项出现过的文档列表，会包含更多其它信息。它会保存每一个词项出现过的文档总数， 在对应的文档中一个具体词项出现的总次数，词项在文档中的顺序，每个文档的长度，所有文档的平均长度，等等。这些统计信息允许 Elasticsearch 决定哪些词比其它词更重要，哪些文档比其它文档更重要，这些内容在&nbsp;<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/relevance-intro.html" title="什么是相关性?">什么是相关性?</a>&nbsp;中有描述。</p>

<p>为了能够实现预期功能，倒排索引需要知道集合中的&nbsp;<em>所有</em>&nbsp;文档，这是需要认识到的关键问题。</p>

<p>早期的全文检索会为整个文档集合建立一个很大的倒排索引并将其写入到磁盘。 一旦新的索引就绪，旧的就会被其替换，这样最近的变化便可以被检索到。</p>

<h3>不变性</h3>

<p>倒排索引被写入磁盘后是&nbsp;<em>不可改变</em>&nbsp;的:它永远不会修改。&nbsp;不变性有重要的价值：</p>

<ul style="list-style-type:disc">
	<li>不需要锁。如果你从来不更新索引，你就不需要担心多进程同时修改数据的问题。</li>
	<li>一旦索引被读入内核的文件系统缓存，便会留在哪里，由于其不变性。只要文件系统缓存中还有足够的空间，那么大部分读请求会直接请求内存，而不会命中磁盘。这提供了很大的性能提升。</li>
	<li>其它缓存(像filter缓存)，在索引的生命周期内始终有效。它们不需要在每次数据改变时被重建，因为数据不会变化。</li>
	<li>写入单个大的倒排索引允许数据被压缩，减少磁盘 I/O 和 需要被缓存到内存的索引的使用量。</li>
</ul>

<p>当然，一个不变的索引也有不好的地方。主要事实是它是不可变的! 你不能修改它。如果你需要让一个新的文档 可被搜索，你需要重建整个索引。这要么对一个索引所能包含的数据量造成了很大的限制，要么对索引可被更新的频率造成了很大的限制。</p>

<h2>动态更新索引</h2>

<p>下一个需要被解决的问题是怎样在保留不变性的前提下实现倒排索引的更新？&nbsp;答案是: 用更多的索引。</p>

<p>通过增加新的补充索引来反映新近的修改，而不是直接重写整个倒排索引。每一个倒排索引都会被轮流查询到--从最早的开始--查询完后再对结果进行合并。</p>

<p>Elasticsearch 基于 Lucene, 这个 java 库引入了&nbsp;<em>按段搜索</em>&nbsp;的概念。&nbsp;每一&nbsp;<em>段</em>&nbsp;本身都是一个倒排索引， 但&nbsp;<em>索引</em>&nbsp;在 Lucene 中除表示所有&nbsp;<em>段</em>&nbsp;的集合外， 还增加了&nbsp;<em>提交点</em>&nbsp;的概念 &mdash; 一个列出了所有已知段的文件，就像在&nbsp;<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/dynamic-indices.html#img-index-segments" title="图 16. 一个 Lucene 索引包含一个提交点和三个段">图&nbsp;16 &ldquo;一个 Lucene 索引包含一个提交点和三个段&rdquo;</a>&nbsp;中描绘的那样。 如&nbsp;<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/dynamic-indices.html#img-memory-buffer" title="图 17. 一个在内存缓存中包含新文档的 Lucene 索引">图&nbsp;17 &ldquo;一个在内存缓存中包含新文档的 Lucene 索引&rdquo;</a>&nbsp;所示，新的文档首先被添加到内存索引缓存中，然后写入到一个基于磁盘的段，如<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/dynamic-indices.html#img-post-commit" title="图 18. 在一次提交后，一个新的段被添加到提交点而且缓存被清空。">图&nbsp;18 &ldquo;在一次提交后，一个新的段被添加到提交点而且缓存被清空。&rdquo;</a>&nbsp;所示。</p>

<p>&nbsp;</p>

<p><strong>图&nbsp;16.&nbsp;一个 Lucene 索引包含一个提交点和三个段</strong></p>

<p><img alt="A Lucene index with a commit point and three segments" src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/elas_1101.png" /></p>

<p>&nbsp;</p>

<p><strong>索引与分片的比较</strong></p>

<p>被混淆的概念是，一个&nbsp;<em>Lucene 索引</em>&nbsp;我们在 Elasticsearch 称作&nbsp;<em>分片</em>&nbsp;。 一个 Elasticsearch&nbsp;<em>索引</em>是分片的集合。 当 Elasticsearch 在索引中搜索的时候， 他发送查询到每一个属于索引的分片(Lucene 索引)，然后像&nbsp;<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/distributed-search.html" title="执行分布式检索"><em>执行分布式检索</em></a>&nbsp;提到的那样，合并每个分片的结果到一个全局的结果集。</p>

<p>逐段搜索会以如下流程进行工作：</p>

<ol style="list-style-type:decimal">
	<li>新文档被收集到内存索引缓存， 见&nbsp;<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/dynamic-indices.html#img-memory-buffer" title="图 17. 一个在内存缓存中包含新文档的 Lucene 索引">图&nbsp;17 &ldquo;一个在内存缓存中包含新文档的 Lucene 索引&rdquo;</a>&nbsp;。</li>
	<li>
	<p>不时地, 缓存被&nbsp;<em>提交</em>&nbsp;：</p>

	<ul style="list-style-type:disc">
		<li>一个新的段--一个追加的倒排索引--被写入磁盘。</li>
		<li>一个新的包含新段名字的&nbsp;<em>提交点</em>&nbsp;被写入磁盘。</li>
		<li>磁盘进行&nbsp;<em>同步</em>&nbsp;&mdash; 所有在文件系统缓存中等待的写入都刷新到磁盘，以确保它们被写入物理文件。</li>
	</ul>
	</li>
	<li>新的段被开启，让它包含的文档可见以被搜索。</li>
	<li>内存缓存被清空，等待接收新的文档。</li>
</ol>

<p>&nbsp;</p>

<p><strong>图&nbsp;17.&nbsp;一个在内存缓存中包含新文档的 Lucene 索引</strong></p>

<p><img alt="A Lucene index with new documents in the in-memory buffer, ready to commit" src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/elas_1102.png" /></p>

<p>&nbsp;</p>

<p>&nbsp;</p>

<p><strong>图&nbsp;18.&nbsp;在一次提交后，一个新的段被添加到提交点而且缓存被清空。</strong></p>

<p><img alt="After a commit, a new segment is added to the index and the buffer is cleared" src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/elas_1103.png" /></p>

<p>&nbsp;</p>

<p>当一个查询被触发，所有已知的段按顺序被查询。词项统计会对所有段的结果进行聚合，以保证每个词和每个文档的关联都被准确计算。 这种方式可以用相对较低的成本将新文档添加到索引。</p>

<h3>删除和更新</h3>

<p>段是不可改变的，所以既不能从把文档从旧的段中移除，也不能修改旧的段来进行反映文档的更新。 取而代之的是，每个提交点会包含一个&nbsp;<code>.del</code>&nbsp;文件，文件中会列出这些被删除文档的段信息。</p>

<p>当一个文档被 &ldquo;删除&rdquo; 时，它实际上只是在&nbsp;<code>.del</code>&nbsp;文件中被&nbsp;<em>标记</em>&nbsp;删除。一个被标记删除的文档仍然可以被查询匹配到， 但它会在最终结果被返回前从结果集中移除。</p>

<p>文档更新也是类似的操作方式：当一个文档被更新时，旧版本文档被标记删除，文档的新版本被索引到一个新的段中。 可能两个版本的文档都会被一个查询匹配到，但被删除的那个旧版本文档在结果集返回前就已经被移除。</p>

<p>在&nbsp;<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/merge-process.html" title="段合并">段合并</a>&nbsp;, 我们展示了一个被删除的文档是怎样被文件系统移除的。</p>

<h2>近实时搜索</h2>

<p>随着按段（per-segment）搜索的发展，&nbsp;一个新的文档从索引到可被搜索的延迟显著降低了。新文档在几分钟之内即可被检索，但这样还是不够快。</p>

<p>磁盘在这里成为了瓶颈。&nbsp;提交（Commiting）一个新的段到磁盘需要一个&nbsp;<a href="http://en.wikipedia.org/wiki/Fsync" target="_top"><code>fsync</code></a>&nbsp;来确保段被物理性地写入磁盘，这样在断电的时候就不会丢失数据。 但是&nbsp;<code>fsync</code>&nbsp;操作代价很大; 如果每次索引一个文档都去执行一次的话会造成很大的性能问题。</p>

<p>我们需要的是一个更轻量的方式来使一个文档可被搜索，这意味着&nbsp;<code>fsync</code>&nbsp;要从整个过程中被移除。</p>

<p>在Elasticsearch和磁盘之间是文件系统缓存。&nbsp;像之前描述的一样， 在内存索引缓冲区（&nbsp;<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/near-real-time.html#img-pre-refresh" title="图 19. 在内存缓冲区中包含了新文档的 Lucene 索引">图&nbsp;19 &ldquo;在内存缓冲区中包含了新文档的 Lucene 索引&rdquo;</a>&nbsp;）中的文档会被写入到一个新的段中（&nbsp;<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/near-real-time.html#img-post-refresh" title="图 20. 缓冲区的内容已经被写入一个可被搜索的段中，但还没有进行提交">图&nbsp;20 &ldquo;缓冲区的内容已经被写入一个可被搜索的段中，但还没有进行提交&rdquo;</a>&nbsp;）。 但是这里新段会被先写入到文件系统缓存--这一步代价会比较低，稍后再被刷新到磁盘--这一步代价比较高。不过只要文件已经在缓存中， 就可以像其它文件一样被打开和读取了。</p>

<p><strong>图&nbsp;19.&nbsp;在内存缓冲区中包含了新文档的 Lucene 索引</strong></p>

<p><img alt="A Lucene index with new documents in the in-memory buffer" src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/elas_1104.png" /></p>

<p>&nbsp;</p>

<p>Lucene 允许新段被写入和打开--使其包含的文档在未进行一次完整提交时便对搜索可见。 这种方式比进行一次提交代价要小得多，并且在不影响性能的前提下可以被频繁地执行。</p>

<p><strong>图&nbsp;20.&nbsp;缓冲区的内容已经被写入一个可被搜索的段中，但还没有进行提交</strong></p>

<p><img alt="The buffer contents have been written to a segment, which is searchable, but is not yet commited" src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/elas_1105.png" /></p>

<p>&nbsp;</p>

<h3>refresh API</h3>

<p>在 Elasticsearch 中，写入和打开一个新段的轻量的过程叫做&nbsp;<em>refresh</em>&nbsp;。&nbsp;默认情况下每个分片会每秒自动刷新一次。这就是为什么我们说 Elasticsearch 是&nbsp;<em>近</em>&nbsp;实时搜索: 文档的变化并不是立即对搜索可见，但会在一秒之内变为可见。</p>

<p>这些行为可能会对新用户造成困惑: 他们索引了一个文档然后尝试搜索它，但却没有搜到。这个问题的解决办法是用&nbsp;<code>refresh</code>&nbsp;API 执行一次手动刷新:</p>

<pre>
POST /_refresh <img alt="" src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/icons/callouts/1.png" />
POST /blogs/_refresh <img alt="" src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/icons/callouts/2.png" /></pre>

<table border="0" summary="Callout list">
	<tbody>
		<tr>
			<td style="vertical-align:top">
			<p><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/near-real-time.html#CO37-1"><img alt="" src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/icons/callouts/1.png" /></a></p>
			</td>
			<td style="vertical-align:top">
			<p>刷新（Refresh）所有的索引。</p>
			</td>
		</tr>
		<tr>
			<td style="vertical-align:top">
			<p><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/near-real-time.html#CO37-2"><img alt="" src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/icons/callouts/2.png" /></a></p>
			</td>
			<td style="vertical-align:top">
			<p>只刷新（Refresh）&nbsp;<code>blogs</code>&nbsp;索引。</p>
			</td>
		</tr>
	</tbody>
</table>

<p><img alt="提示" src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/icons/tip.png" /></p>

<p>尽管刷新是比提交轻量很多的操作，它还是会有性能开销。&nbsp;当写测试的时候， 手动刷新很有用，但是不要在生产环境下每次索引一个文档都去手动刷新。 相反，你的应用需要意识到 Elasticsearch 的近实时的性质，并接受它的不足。</p>

<p>并不是所有的情况都需要每秒刷新。可能你正在使用 Elasticsearch 索引大量的日志文件， 你可能想优化索引速度而不是近实时搜索， 可以通过设置&nbsp;<code>refresh_interval</code>&nbsp;， 降低每个索引的刷新频率：</p>

<pre>
PUT /my_logs
{
  &quot;settings&quot;: {
    &quot;refresh_interval&quot;: &quot;30s&quot; <img alt="" src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/icons/callouts/1.png" />
  }
}</pre>

<table border="0" summary="Callout list">
	<tbody>
		<tr>
			<td style="vertical-align:top">
			<p><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/near-real-time.html#CO38-1"><img alt="" src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/icons/callouts/1.png" /></a></p>
			</td>
			<td style="vertical-align:top">
			<p>每30秒刷新&nbsp;<code>my_logs</code>&nbsp;索引。</p>
			</td>
		</tr>
	</tbody>
</table>

<p><code>refresh_interval</code>&nbsp;可以在既存索引上进行动态更新。 在生产环境中，当你正在建立一个大的新索引时，可以先关闭自动刷新，待开始使用该索引时，再把它们调回来：</p>

<pre>
PUT /my_logs/_settings
{ &quot;refresh_interval&quot;: -1 } <img alt="" src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/icons/callouts/1.png" />

PUT /my_logs/_settings
{ &quot;refresh_interval&quot;: &quot;1s&quot; } <img alt="" src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/icons/callouts/2.png" /></pre>

<table border="0" summary="Callout list">
	<tbody>
		<tr>
			<td style="vertical-align:top">
			<p><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/near-real-time.html#CO39-1"><img alt="" src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/icons/callouts/1.png" /></a></p>
			</td>
			<td style="vertical-align:top">
			<p>关闭自动刷新。</p>
			</td>
		</tr>
		<tr>
			<td style="vertical-align:top">
			<p><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/near-real-time.html#CO39-2"><img alt="" src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/icons/callouts/2.png" /></a></p>
			</td>
			<td style="vertical-align:top">
			<p>每秒自动刷新。</p>
			</td>
		</tr>
	</tbody>
</table>

<p><img alt="小心" src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/icons/caution.png" /></p>

<p><code>refresh_interval</code>&nbsp;需要一个&nbsp;<em>持续时间</em>&nbsp;值， 例如&nbsp;<code>1s</code>&nbsp;（1 秒） 或&nbsp;<code>2m</code>&nbsp;（2 分钟）。 一个绝对值&nbsp;<em>1</em>&nbsp;表示的是&nbsp;<em>1毫秒</em>&nbsp;--无疑会使你的集群陷入瘫痪。</p>

<h2>持久化变更</h2>

<p>如果没有用&nbsp;<code>fsync</code>&nbsp;把数据从文件系统缓存刷（flush）到硬盘，我们不能保证数据在断电甚至是程序正常退出之后依然存在。为了保证 Elasticsearch 的可靠性，需要确保数据变化被持久化到磁盘。</p>

<p>在&nbsp;<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/dynamic-indices.html" title="动态更新索引">动态更新索引</a>，我们说一次完整的提交会将段刷到磁盘，并写入一个包含所有段列表的提交点。Elasticsearch 在启动或重新打开一个索引的过程中使用这个提交点来判断哪些段隶属于当前分片。</p>

<p>即使通过每秒刷新（refresh）实现了近实时搜索，我们仍然需要经常进行完整提交来确保能从失败中恢复。但在两次提交之间发生变化的文档怎么办？我们也不希望丢失掉这些数据。</p>

<p>Elasticsearch 增加了一个&nbsp;<em>translog</em>&nbsp;，或者叫事务日志，在每一次对 Elasticsearch 进行操作时均进行了日志记录。通过 translog ，整个流程看起来是下面这样：</p>

<ol style="list-style-type:decimal">
	<li>
	<p>一个文档被索引之后，就会被添加到内存缓冲区，<em>并且</em>&nbsp;追加到了 translog ，正如&nbsp;<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/translog.html#img-xlog-pre-refresh" title="图 21. 新的文档被添加到内存缓冲区并且被追加到了事务日志">图&nbsp;21 &ldquo;新的文档被添加到内存缓冲区并且被追加到了事务日志&rdquo;</a>&nbsp;描述的一样。</p>

	<p><strong>图&nbsp;21.&nbsp;新的文档被添加到内存缓冲区并且被追加到了事务日志</strong></p>

	<p><img alt="New documents are added to the in-memory buffer and appended to the transaction log" src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/elas_1106.png" /></p>
	</li>
	<li>
	<p>刷新（refresh）使分片处于&nbsp;<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/translog.html#img-xlog-post-refresh" title="图 22. 刷新（refresh）完成后, 缓存被清空但是事务日志不会">图&nbsp;22 &ldquo;刷新（refresh）完成后, 缓存被清空但是事务日志不会&rdquo;</a>&nbsp;描述的状态，分片每秒被刷新（refresh）一次：</p>

	<ul style="list-style-type:disc">
		<li>这些在内存缓冲区的文档被写入到一个新的段中，且没有进行&nbsp;<code>fsync</code>&nbsp;操作。</li>
		<li>这个段被打开，使其可被搜索。</li>
		<li>内存缓冲区被清空。</li>
	</ul>

	<p><strong>图&nbsp;22.&nbsp;刷新（refresh）完成后, 缓存被清空但是事务日志不会</strong></p>

	<p><img alt="After a refresh, the buffer is cleared but the transaction log is not" src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/elas_1107.png" /></p>
	</li>
	<li>
	<p>这个进程继续工作，更多的文档被添加到内存缓冲区和追加到事务日志（见&nbsp;<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/translog.html#img-xlog-pre-flush" title="图 23. 事务日志不断积累文档">图&nbsp;23 &ldquo;事务日志不断积累文档&rdquo;</a>&nbsp;）。</p>

	<p><strong>图&nbsp;23.&nbsp;事务日志不断积累文档</strong></p>

	<p><img alt="The transaction log keeps accumulating documents" src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/elas_1108.png" /></p>
	</li>
	<li>
	<p>每隔一段时间--例如 translog 变得越来越大--索引被刷新（flush）；一个新的 translog 被创建，并且一个全量提交被执行（见&nbsp;<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/translog.html#img-xlog-post-flush" title="图 24. 在刷新（flush）之后，段被全量提交，并且事务日志被清空">图&nbsp;24 &ldquo;在刷新（flush）之后，段被全量提交，并且事务日志被清空&rdquo;</a>）：</p>

	<ul style="list-style-type:disc">
		<li>所有在内存缓冲区的文档都被写入一个新的段。</li>
		<li>缓冲区被清空。</li>
		<li>一个提交点被写入硬盘。</li>
		<li>文件系统缓存通过&nbsp;<code>fsync</code>&nbsp;被刷新（flush）。</li>
		<li>老的 translog 被删除。</li>
	</ul>
	</li>
</ol>

<p>translog 提供所有还没有被刷到磁盘的操作的一个持久化纪录。当 Elasticsearch 启动的时候， 它会从磁盘中使用最后一个提交点去恢复已知的段，并且会重放 translog 中所有在最后一次提交后发生的变更操作。</p>

<p>translog 也被用来提供实时 CRUD 。当你试着通过ID查询、更新、删除一个文档，它会在尝试从相应的段中检索之前， 首先检查 translog 任何最近的变更。这意味着它总是能够实时地获取到文档的最新版本。</p>

<p><strong>图&nbsp;24.&nbsp;在刷新（flush）之后，段被全量提交，并且事务日志被清空</strong></p>

<p><img alt="After a flush, the segments are fully commited and the transaction log is cleared" src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/elas_1109.png" /></p>

<p>&nbsp;</p>

<h3>flush API</h3>

<p>这个执行一个提交并且截断 translog 的行为在 Elasticsearch 被称作一次&nbsp;<em>flush</em>&nbsp;。&nbsp;分片每30分钟被自动刷新（flush），或者在 translog 太大的时候也会刷新。请查看&nbsp;<a href="https://www.elastic.co/guide/en/elasticsearch/reference/2.4/index-modules-translog.html#_translog_settings" target="_top"><code>translog</code>&nbsp;文档</a>&nbsp;来设置，它可以用来&nbsp;控制这些阈值：</p>

<p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.6/indices-flush.html" target="_top"><code>flush</code>&nbsp;API</a>&nbsp;可以&nbsp;被用来执行一个手工的刷新（flush）:</p>

<pre>
POST /blogs/_flush <img alt="" src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/icons/callouts/1.png" />

POST /_flush?wait_for_ongoing <img alt="" src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/icons/callouts/2.png" /></pre>

<table border="0" summary="Callout list">
	<tbody>
		<tr>
			<td style="vertical-align:top">
			<p><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/translog.html#CO40-1"><img alt="" src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/icons/callouts/1.png" /></a></p>
			</td>
			<td style="vertical-align:top">
			<p>刷新（flush）&nbsp;<code>blogs</code>&nbsp;索引。</p>
			</td>
		</tr>
		<tr>
			<td style="vertical-align:top">
			<p><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/translog.html#CO40-2"><img alt="" src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/icons/callouts/2.png" /></a></p>
			</td>
			<td style="vertical-align:top">
			<p>刷新（flush）所有的索引并且并且等待所有刷新在返回前完成。</p>
			</td>
		</tr>
	</tbody>
</table>

<p>你很少需要自己手动执行一个的&nbsp;<code>flush</code>&nbsp;操作；通常情况下，自动刷新就足够了。</p>

<p>这就是说，在重启节点或关闭索引之前执行&nbsp;<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/translog.html#flush-api" title="flush API">flush</a>&nbsp;有益于你的索引。当 Elasticsearch 尝试恢复或重新打开一个索引， 它需要重放 translog 中所有的操作，所以如果日志越短，恢复越快。</p>

<p><strong>Translog 有多安全?</strong></p>

<p>translog 的目的是保证操作不会丢失。这引出了这个问题： Translog 有多安全&nbsp;？</p>

<p>在文件被&nbsp;<code>fsync</code>&nbsp;到磁盘前，被写入的文件在重启之后就会丢失。默认 translog 是每 5 秒被<code>fsync</code>&nbsp;刷新到硬盘， 或者在每次写请求完成之后执行(e.g. index, delete, update, bulk)。这个过程在主分片和复制分片都会发生。最终， 基本上，这意味着在整个请求被&nbsp;<code>fsync</code>&nbsp;到主分片和复制分片的translog之前，你的客户端不会得到一个 200 OK 响应。</p>

<p>在每次请求后都执行一个 fsync 会带来一些性能损失，尽管实践表明这种损失相对较小（特别是bulk导入，它在一次请求中平摊了大量文档的开销）。</p>

<p>但是对于一些大容量的偶尔丢失几秒数据问题也并不严重的集群，使用异步的 fsync 还是比较有益的。比如，写入的数据被缓存到内存中，再每5秒执行一次&nbsp;<code>fsync</code>&nbsp;。</p>

<p>这个行为可以通过设置&nbsp;<code>durability</code>&nbsp;参数为&nbsp;<code>async</code>&nbsp;来启用：</p>

<pre>
PUT /my_index/_settings
{
    &quot;index.translog.durability&quot;: &quot;async&quot;,
    &quot;index.translog.sync_interval&quot;: &quot;5s&quot;
}</pre>

<p>这个选项可以针对索引单独设置，并且可以动态进行修改。如果你决定使用异步 translog 的话，你需要&nbsp;<em>保证</em>&nbsp;在发生crash时，丢失掉&nbsp;<code>sync_interval</code>&nbsp;时间段的数据也无所谓。请在决定前知晓这个特性。</p>

<p>如果你不确定这个行为的后果，最好是使用默认的参数（&nbsp;<code>&quot;index.translog.durability&quot;: &quot;request&quot;</code>&nbsp;）来避免数据丢失。</p>

<h2>段合并</h2>

<p>由于自动刷新流程每秒会创建一个新的段&nbsp;，这样会导致短时间内的段数量暴增。而段数目太多会带来较大的麻烦。 每一个段都会消耗文件句柄、内存和cpu运行周期。更重要的是，每个搜索请求都必须轮流检查每个段；所以段越多，搜索也就越慢。</p>

<p>Elasticsearch通过在后台进行段合并来解决这个问题。小的段被合并到大的段，然后这些大的段再被合并到更大的段。</p>

<p>段合并的时候会将那些旧的已删除文档&nbsp;从文件系统中清除。&nbsp;被删除的文档（或被更新文档的旧版本）不会被拷贝到新的大段中。</p>

<p>启动段合并不需要你做任何事。进行索引和搜索时会自动进行。这个流程像在&nbsp;<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/merge-process.html#img-merge" title="图 25. 两个提交了的段和一个未提交的段正在被合并到一个更大的段">图&nbsp;25 &ldquo;两个提交了的段和一个未提交的段正在被合并到一个更大的段&rdquo;</a>&nbsp;中提到的一样工作：</p>

<p>1、 当索引的时候，刷新（refresh）操作会创建新的段并将段打开以供搜索使用。</p>

<p>2、 合并进程选择一小部分大小相似的段，并且在后台将它们合并到更大的段中。这并不会中断索引和搜索。</p>

<p>&nbsp;</p>

<p><strong>图&nbsp;25.&nbsp;两个提交了的段和一个未提交的段正在被合并到一个更大的段</strong></p>

<p><img alt="Two commited segments and one uncommited segment in the process of being merged into a bigger segment" src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/elas_1110.png" /></p>

<p>&nbsp;</p>

<p>3、&nbsp;<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/merge-process.html#img-post-merge" title="图 26. 一旦合并结束，老的段被删除">图&nbsp;26 &ldquo;一旦合并结束，老的段被删除&rdquo;</a>&nbsp;说明合并完成时的活动：</p>

<ul style="list-style-type:disc">
	<li>新的段被刷新（flush）到了磁盘。 &nbsp; ** 写入一个包含新段且排除旧的和较小的段的新提交点。</li>
	<li>新的段被打开用来搜索。</li>
	<li>老的段被删除。</li>
</ul>

<p>&nbsp;</p>

<p><strong>图&nbsp;26.&nbsp;一旦合并结束，老的段被删除</strong></p>

<p><img alt="一旦合并结束，老的段被删除" src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/elas_1111.png" /></p>

<p>&nbsp;</p>

<p>合并大的段需要消耗大量的I/O和CPU资源，如果任其发展会影响搜索性能。Elasticsearch在默认情况下会对合并流程进行资源限制，所以搜索仍然 有足够的资源很好地执行。</p>

<p><img alt="提示" src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/icons/tip.png" /></p>

<p>查看&nbsp;<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/indexing-performance.html#segments-and-merging" title="段和合并">段和合并</a>&nbsp;来为你的实例获取关于合并调整的建议。</p>

<h3>optimize API</h3>

<p><code>optimize</code>&nbsp;API大可看做是&nbsp;<em>强制合并</em>&nbsp;API&nbsp;。它会将一个分片强制合并到&nbsp;<code>max_num_segments</code>&nbsp;参数指定大小的段数目。 这样做的意图是减少段的数量（通常减少到一个），来提升搜索性能。</p>

<p><img alt="警告" src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/icons/warning.png" /></p>

<p><code>optimize</code>&nbsp;API&nbsp;<em>不应该</em>&nbsp;被用在一个动态索引&mdash;&mdash;&mdash;&mdash;一个正在被活跃更新的索引。后台合并流程已经可以很好地完成工作。 optimizing 会阻碍这个进程。不要干扰它！</p>

<p>在特定情况下，使用&nbsp;<code>optimize</code>&nbsp;API 颇有益处。例如在日志这种用例下，每天、每周、每月的日志被存储在一个索引中。 老的索引实质上是只读的；它们也并不太可能会发生变化。</p>

<p>在这种情况下，使用optimize优化老的索引，将每一个分片合并为一个单独的段就很有用了；这样既可以节省资源，也可以使搜索更加快速：</p>

<pre>
POST /logstash-2014-10/_optimize?max_num_segments=1 <img alt="" src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/icons/callouts/1.png" /></pre>

<table border="0" summary="Callout list">
	<tbody>
		<tr>
			<td style="vertical-align:top">
			<p><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/merge-process.html#CO41-1"><img alt="" src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/icons/callouts/1.png" /></a></p>
			</td>
			<td style="vertical-align:top">
			<p>合并索引中的每个分片为一个单独的段</p>
			</td>
		</tr>
	</tbody>
</table>

<p><img alt="警告" src="https://www.elastic.co/guide/cn/elasticsearch/guide/current/images/icons/warning.png" /></p>

<p>请注意，使用&nbsp;<code>optimize</code>&nbsp;API 触发段合并的操作一点也不会受到任何资源上的限制。这可能会消耗掉你节点上全部的I/O资源, 使其没有余裕来处理搜索请求，从而有可能使集群失去响应。 如果你想要对索引执行 `optimize`，你需要先使用分片分配（查看&nbsp;<a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/retiring-data.html#migrate-indices" title="迁移旧索引">迁移旧索引</a>）把索引移到一个安全的节点，再执行。</p>

				    </section>
					</article>
				</main>
            </div>
        </div>
    </section>
    <a href="#top" id="goTop" ><i class="fa fa-angle-up fa-3x"></i></a>
	<script src="../js/jquery.min.js"></script>
    <script type="text/javascript" src="../js/datas/detailAngularJs.js"></script>
    <script src="../plugins/scrolltopcontrol.js"></script>
</body>
</html>